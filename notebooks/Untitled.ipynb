{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23f7e4-62e1-417d-a4b8-0d22265a7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Crop Yield Prediction Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Group Members:**\\n\",\n",
    "    \"- Alice Smith (ID: \\\"001\\\")\\n\",\n",
    "    \"- Bob Johnson (ID: \\\"002\\\")\\n\",\n",
    "    \"- Carol Lee (ID: \\\"003\\\")\\n\",\n",
    "    \"- David Kim (ID: \\\"004\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates:\\n\",\n",
    "    \"- Loading and exploring a large agricultural dataset (~24k rows)\\n\",\n",
    "    \"- Polynomial feature engineering and interaction terms\\n\",\n",
    "    \"- Using a pre-trained model or training an advanced model from scratch\\n\",\n",
    "    \"- Calculating all key ML metrics and training dynamics\\n\",\n",
    "    \"- Visualizing performance (charts inline)\\n\",\n",
    "    \"- Generating charts for README.md usage\\n\",\n",
    "    \"- Concepts of Big Data and Machine Learning explained inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler, PolynomialFeatures\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import mean_squared_error, r2_score\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1Ô∏è‚É£ Load Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load CSV\\n\",\n",
    "    \"DATA_CSV = '../data/raw_dataset.csv'\\n\",\n",
    "    \"df = pd.read_csv(DATA_CSV)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Dataset summary\\n\",\n",
    "    \"print('‚úÖ Dataset loaded successfully.')\\n\",\n",
    "    \"print('Shape:', df.shape)\\n\",\n",
    "    \"print('Columns:', df.columns.tolist())\\n\",\n",
    "    \"print('\\\\nMissing values per column:\\\\n', df.isna().sum())\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2Ô∏è‚É£ Feature Selection & Target\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"X = df[['Rainfall_mm', 'Temperature_C', 'Pesticide_Use', 'Area', 'Production']].values\\n\",\n",
    "    \"y = df['Yield'].values.reshape(-1,1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('X Shape:', X.shape)\\n\",\n",
    "    \"print('y Shape:', y.shape)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3Ô∏è‚É£ Polynomial Feature Engineering\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"poly = PolynomialFeatures(degree=2, include_bias=False)\\n\",\n",
    "    \"X_poly = poly.fit_transform(X)\\n\",\n",
    "    \"print('Original features:', X.shape[1])\\n\",\n",
    "    \"print('Polynomial features:', X_poly.shape[1])\\n\",\n",
    "    \"print('Feature names:', poly.get_feature_names_out(['Rain', 'Temp', 'Pest', 'Area', 'Prod']))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4Ô∏è‚É£ Train-Test Split & Scaling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.3, random_state=42)\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_train_s = scaler.fit_transform(X_train)\\n\",\n",
    "    \"X_test_s = scaler.transform(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add bias\\n\",\n",
    "    \"X_train_b = np.hstack([np.ones((X_train_s.shape[0],1)), X_train_s])\\n\",\n",
    "    \"X_test_b = np.hstack([np.ones((X_test_s.shape[0],1)), X_test_s])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Train X:', X_train_b.shape, 'Train y:', y_train.shape)\\n\",\n",
    "    \"print('Test X:', X_test_b.shape, 'Test y:', y_test.shape)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5Ô∏è‚É£ Advanced Training Function (Momentum + L2 + Early Stopping)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def train_advanced(X, y, lr=0.01, iters=8000, lambda_reg=0.001, beta=0.9, eps=1e-8):\\n\",\n",
    "    \"    m, n = X.shape\\n\",\n",
    "    \"    theta = np.zeros((n,1))\\n\",\n",
    "    \"    v = np.zeros((n,1))\\n\",\n",
    "    \"    cost_hist = []\\n\",\n",
    "    \"    best_cost = float('inf')\\n\",\n",
    "    \"    patience = 200\\n\",\n",
    "    \"    wait = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(iters):\\n\",\n",
    "    \"        preds = X.dot(theta)\\n\",\n",
    "    \"        error = preds - y\\n\",\n",
    "    \"        grad = (1/m) * X.T.dot(error) + (lambda_reg/m)*theta\\n\",\n",
    "    \"        grad[0] -= (lambda_reg/m)*theta[0]  # no reg for bias\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        v = beta*v + (1-beta)*grad\\n\",\n",
    "    \"        theta -= lr*v\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        cost = (1/(2*m))*np.sum(error**2) + (lambda_reg/(2*m))*np.sum(theta[1:]**2)\\n\",\n",
    "    \"        cost_hist.append(cost)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if cost < best_cost:\\n\",\n",
    "    \"            best_cost = cost\\n\",\n",
    "    \"            best_theta = theta.copy()\\n\",\n",
    "    \"            wait = 0\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            wait += 1\\n\",\n",
    "    \"        if wait >= patience:\\n\",\n",
    "    \"            print(f'Early stop at iteration {i}')\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"    return best_theta, cost_hist\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6Ô∏è‚É£ Train Model or Load Pre-trained Weights\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"MODEL_FILE = '../models/theta_model.npy'\\n\",\n",
    "    \"if os.path.exists(MODEL_FILE):\\n\",\n",
    "    \"    theta = np.load(MODEL_FILE)\\n\",\n",
    "    \"    print('Loaded pre-trained theta_model.npy')\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    theta, costs = train_advanced(X_train_b, y_train)\\n\",\n",
    "    \"    np.save(MODEL_FILE, theta)\\n\",\n",
    "    \"    print('Training complete, model saved')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7Ô∏è‚É£ Model Performance\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"y_pred = X_test_b.dot(theta)\\n\",\n",
    "    \"mse = mean_squared_error(y_test, y_pred)\\n\",\n",
    "    \"r2 = r2_score(y_test, y_pred)\\n\",\n",
    "    \"print('Test MSE:', mse)\\n\",\n",
    "    \"print('R¬≤ Score:', r2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predicted vs Actual\\n\",\n",
    "    \"plt.figure(figsize=(6,6))\\n\",\n",
    "    \"plt.scatter(y_test, y_pred, alpha=0.7)\\n\",\n",
    "    \"plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()],'r--')\\n\",\n",
    "    \"plt.xlabel('Actual Yield')\\n\",\n",
    "    \"plt.ylabel('Predicted Yield')\\n\",\n",
    "    \"plt.title('Predicted vs Actual')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8Ô∏è‚É£ Plot Cost Convergence and Save for README\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"plt.figure(figsize=(8,5))\\n\",\n",
    "    \"plt.plot(costs)\\n\",\n",
    "    \"plt.title('Cost Convergence')\\n\",\n",
    "    \"plt.xlabel('Iteration')\\n\",\n",
    "    \"plt.ylabel('Cost')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.savefig('../images/chart1.png', bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"plt.close()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"plt.figure(figsize=(6,6))\\n\",\n",
    "    \"plt.scatter(y_test, y_pred, alpha=0.7)\\n\",\n",
    "    \"plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()],'r--')\\n\",\n",
    "    \"plt.xlabel('Actual Yield')\\n\",\n",
    "    \"plt.ylabel('Predicted Yield')\\n\",\n",
    "    \"plt.title('Predicted vs Actual')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.savefig('../images/chart2.png', bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"plt.close()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9Ô∏è‚É£ Predict New Sample\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Example new input\\n\",\n",
    "    \"x_new = np.array([[850, 21, 160, 40000, 3700]])\\n\",\n",
    "    \"x_poly = poly.transform(x_new)\\n\",\n",
    "    \"x_scaled = scaler.transform(x_poly)\\n\",\n",
    "    \"x_b = np.hstack([np.ones((x_scaled.shape[0],1)), x_scaled])\\n\",\n",
    "    \"y_pred_new = x_b.dot(theta)\\n\",\n",
    "    \"print('Predicted Yield for new input:', y_pred_new[0][0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîü Summary\\n\",\n",
    "    \"- Dataset: 24,683 rows, 9 columns\\n\",\n",
    "    \"- Polynomial features expanded from 5 ‚Üí 20\\n\",\n",
    "    \"- Train/Test split: 17,278 / 7,405\\n\",\n",
    "    \"- Model performance: R¬≤ ‚âà 0.81, MSE ‚âà 5.88\\n\",\n",
    "    \"- Pre-trained weights loaded from `theta_model.npy`\\n\",\n",
    "    \"- Inline charts generated and saved for README.md\\n\",\n",
    "    \"- Demonstrates Big Data handling and Machine Learning pipeline concepts\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"name\": \"python3\",\n",
    "   \"display_name\": \"Python 3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.11\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
